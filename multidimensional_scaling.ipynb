{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another way to do dimensionality reduction.  \n",
    "Designed to bring objects, aka stimuli, down to a low-dimensional (Euclidean) space.\n",
    "Basically, reduce things to 2 or 3 dimensions, and ensure distances represent difference between stimuli.\n",
    "\n",
    "So, factor analysis had interpretations of factors as high-dimensional vectors, which we project down to a lower-dimensional space.\n",
    "MDS is thought of in terms of points, brought down to low-dimensional space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Similarity\n",
    "\n",
    "We have multiple approaches to measuring similarity between two stimuli.  \n",
    "In other analysis approaches, the similarity measures we used were correlations and covariances.\n",
    "However, there's different ways we can do this (we can also equivalently have measures of *dissimilarity*)\n",
    "For MDS, we have two categories:\n",
    "\n",
    "1. Direct Similarities\n",
    "    - Pairwise similarities/dissimilarities\n",
    "    - Sorting task: For example, define similarity by sorting objects into groups, and objects are similar if they are in the same group.\n",
    "    - Condition rank order: We define similarity by ordering objects based on their similarity to some reference point (e.g. rank politicians in order of how similar they are to the politician in office)\n",
    "2. Derived similarities\n",
    "    - Closer to what we've done before, where we do some math based on attributes of objects to calculate a distance metric.\n",
    "\n",
    "I think I've got that accurate to description in lecture, although it seems like all the direct similarities require a distance metric anyway?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS Data\n",
    "\n",
    "For MDS, generally, we don't have sample size requirements.\n",
    "We could do MDS on a single stimulus if desired.\n",
    "\n",
    "Note that in general, we can use either similarities or dissimilarities.\n",
    "However, it is very important to keep track of what we're using.  \n",
    "We also need to have a set of assumptions when we are implementing these methods in software.\n",
    "The convention SPSS uses (and by extension, what we'll use) is that **all measures are dissimilarities**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS Outputs\n",
    "\n",
    "The solution for an MDS is a set of points $X_1, X_2, \\ldots, X_p$ in $r$-dimensional space.\n",
    "Given the goal of visualizing the data, $r$ is typically 2 or 3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric MDS\n",
    "\n",
    "This is the first of several approaches to MDS we'll discuss.\n",
    "Here, data is in a square matrix, $\\Delta$, a dissimilarity matrix.\n",
    "Each matrix is assumed to have 0s on the diagonal, and be symmetric, since each $\\delta_{ij}$ is representing dissimilarity between $i$ and $j$.\n",
    "Obviously, a stimulus should not be dissimilar to itself, and a dissimilarity relation should be symmetric.\n",
    "\n",
    "Now, in our final solution, the distances should preserve the dissimilarity we had to begin with.\n",
    "It will attempt to make the distances as close in value to the dissimilarity as possible, but will necessarily need to approximate.\n",
    "The distances are given as $d_{ij}$.\n",
    "Then we can take all pairs of $d_{ij}$ and $\\delta_{ij}$, and compute a correlation (or squared correlation) to see how close the solution is to the original data.  \n",
    "Note that the correlation should always be positive; a negative correlation is usually an indication that we had similarity dataas inputs, I think.\n",
    "\n",
    "So we have $\\delta_{ij}$ = \"perceived\" dissimilarity between stimuli $i$ and $j$,  \n",
    "$X_{im} = $ position on $m^\\text{th}$ dimension for stimulus $i$, with $m \\in [1, r]$,  \n",
    "$d_{ij} = \\sqrt{\\sum\\limits_{m=1}^r (X_{im} - X_{jm})^2}$, Euclidean distance between $i$ and $j$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric MDS Method\n",
    "\n",
    "Note, \"metric\" MDS is also called \"classical\" MDS.\n",
    "\n",
    "The algorithm is:\n",
    "1. Take matrix $A$ where $a_{ij} = -\\delta_{ij}$\n",
    "and... a couple more steps. We skipped over it pretty quickly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric example\n",
    "\n",
    "Classic example is to consider distances between cities on a map.\n",
    "In theory, this should have a near-perfect 2D solution as an MDS, since the dissimilarities are already 2D (or, if including elevation, 3D) distances.\n",
    "In fact, it should be able to give us a 2D representation that matches what we'd see on a map, although it could show up rotated/flipped relative to a map.  \n",
    "Actually, kind of depends on shape of the original map.\n",
    "First dimension is always the \"most important,\" i.e. the dimension that maximizes distances, I think.\n",
    "So, for US cities, since most spread happens east-west, we have very good chance of east-west being x-axis, and north-south being y-axis, as on a map.\n",
    "For, say, Chile, we'd probably have north-south on the x-axis, since most spread of cities is north to south."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

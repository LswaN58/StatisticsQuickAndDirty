{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Decompositions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Decomposition\n",
    "\n",
    "Given a **symmetric matrix** $A$, we can decompose into the form $A = P\\Lambda P^T$, where $P$ is a matrix whose columns are **eigenvectors**, and $\\Lambda$ is a diagonal matrix, whose diagonals contain **eigenvalues**, in descending order from left to right.  \n",
    "This is often called the **spectral decomposition**.\n",
    "\n",
    "Note, not entirely sure if symmetry is required, or if it's coincidental, and we're just currently thinking about our symmetric matrix.\n",
    "\n",
    "All **symmetric** matrices are square; suppose $A$ is $n \\times n$.\n",
    "Then $P$ and $\\Lambda$ are $n \\times n$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvectors and Eigenvalues\n",
    "\n",
    "The **eigenvectors** and **eigenvalues** have some useful properties.\n",
    "\n",
    "**eigenvector** properties:\n",
    "- All **eigenvectors** $\\vec{e}$ are normalized\n",
    "- All **eigenvectors** are mutually orthogonal\n",
    "\n",
    "Sum over all eigenvalues gives us the total variance of the matrix, I guess.\n",
    "And taking an eigenvalue over the sum gives us the \"importance\" of that component.\n",
    "We refer to the eigenvectors that make up the columns of $P$ as components.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "\n",
    "Similar to the spectral decomposition, we can perform a decomposition on a general matrix $A$, with dimensions $n \\times p$.\n",
    "That is, matrices that are not necessarily symetric (or positive or definite).\n",
    "In this case, we have $A = P \\Lambda Q'$, where $P$ and $Q$ are not necessarily equal.\n",
    "\n",
    "However, if we compute a correlation matrix (maybe you could do covariance too, not quite sure) from general $A$, then the spectral decomposition of that symmetric matrix will have the same $P$ and $\\Lambda$ as the singular value decomposition.\n",
    "\n",
    "So, after performing SVD, we have $\\Lambda$ with **eigenvalues** in descending order.\n",
    "The first component, then, is the most \"important.\"\n",
    "It best represents the variability within the original matrix $A$.\n",
    "We can then take the first **eigenvector**, $\\vec{e_1}$, the first **eigenvalue** $e_1$, and a row vector of $\\vec{e_1}$, which we could denote as $\\vec{e_1}^T$.\n",
    "Then $\\vec{e_1} \\cdot e_1 \\cdot \\vec{e_1}^T$ is an approximation of the original $A$.\n",
    "\n",
    "We can instead take, say, the first two **eigenvectors** and **eigenvalues** of the decomposition, and get a better approximation of $A$, and so forth.\n",
    "\n",
    "Also note, initially each variable in original matrix is equivalent to an eigenvalue of 1, so an eigenvalue > 1 indicates the corresponding eigenvector gives more information than an original variable would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      "          0         1         2         3         4\n",
      "0  0.445258  7.372919  7.252065  1.166756  6.950437\n",
      "1  2.420977  6.700241  5.846414  8.957586  6.400166\n",
      "2  2.270033  7.445409  5.215288  8.458579  4.378710\n",
      "3  5.534517  8.919214  9.612851  9.155913  9.660121\n",
      "4  2.159515  8.567953  2.231314  3.736846  0.330785\n",
      "\n",
      "Correlation matrix:\n",
      "          0         1         2         3         4\n",
      "0  1.000000  0.618791  0.492711  0.723730  0.452455\n",
      "1  0.618791  1.000000  0.106710 -0.020105 -0.041315\n",
      "2  0.492711  0.106710  1.000000  0.290315  0.983677\n",
      "3  0.723730 -0.020105  0.290315  1.000000  0.350071\n",
      "4  0.452455 -0.041315  0.983677  0.350071  1.000000\n",
      "\n",
      "The matrix svd:\n",
      "[[-0.36577142 -0.73359366 -0.47609598 -0.31680506 -0.0319183 ]\n",
      " [-0.46212381  0.18810986  0.32575315 -0.45803957  0.6596521 ]\n",
      " [-0.42770267  0.37707254  0.06149814 -0.3997147  -0.71507543]\n",
      " [-0.63090949 -0.18092967  0.3145467   0.68195722 -0.07219689]\n",
      " [-0.26772465  0.50153342 -0.75132939  0.25494473  0.21747429]]\n",
      "[30.59601218  6.61663555  5.75106493  2.27852328  0.40631839]\n",
      "[[-0.20664419 -0.55231494 -0.46565462 -0.48898643 -0.44306256]\n",
      " [ 0.16117686  0.20289442 -0.43434918  0.6402288  -0.57819007]\n",
      " [ 0.14512361 -0.78273484  0.02082708  0.51382154  0.31909085]\n",
      " [ 0.95128793 -0.04999572  0.02826729 -0.28832319 -0.09285689]\n",
      " [ 0.07287394  0.19649088 -0.77024266 -0.06210091  0.59912473]]\n",
      "The correlation svd:\n",
      "[[-0.52096718 -0.41970996  0.1351338   0.64239686 -0.3485712 ]\n",
      " [-0.20133389 -0.70664462 -0.4895097  -0.35556606  0.3067101 ]\n",
      " [-0.51683386  0.3500708  -0.33666586 -0.42485643 -0.56257116]\n",
      " [-0.40478646 -0.1031889   0.76424711 -0.45232518  0.19190688]\n",
      " [-0.507039    0.43737789 -0.21142743  0.27531436  0.65659156]]\n",
      "[2.73063039e+00 1.33730227e+00 9.16111194e-01 1.59561470e-02\n",
      " 1.60078515e-17]\n",
      "[[-0.52096718 -0.20133389 -0.51683386 -0.40478646 -0.507039  ]\n",
      " [-0.41970996 -0.70664462  0.3500708  -0.1031889   0.43737789]\n",
      " [ 0.1351338  -0.4895097  -0.33666586  0.76424711 -0.21142743]\n",
      " [ 0.64239686 -0.35556606 -0.42485643 -0.45232518  0.27531436]\n",
      " [ 0.3485712  -0.3067101   0.56257116 -0.19190688 -0.65659156]]\n"
     ]
    }
   ],
   "source": [
    "mat = pd.DataFrame([[random.random() * 10 for j in range(5)] for i in range(5)])\n",
    "print(f\"Original matrix:\\n{mat}\\n\")\n",
    "\n",
    "correlations = mat.corr()\n",
    "print(f\"Correlation matrix:\\n{correlations}\\n\")\n",
    "\n",
    "mat_svd = np.linalg.svd(mat)\n",
    "corr_svd = np.linalg.svd(correlations)\n",
    "print(f\"The matrix svd:\\n{mat_svd[0]}\\n{mat_svd[1]}\\n{mat_svd[2]}\\nThe correlation svd:\\n{corr_svd[0]}\\n{corr_svd[1]}\\n{corr_svd[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
